{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audiogram\n",
    "The aim of this class is to introduce you to a very common hearing test. The class will enable you to:\n",
    "\n",
    "* Measure the range of sound frequencies that are audible and how hearing sensitivity varies within that range\n",
    "* Understand how the audiogram is affected by hearing disorders such as presbyacusis\n",
    "* Understand how hearing disorders affect your ability to hear complex sounds, such as speech\n",
    "\n",
    "## Introduction to the audiogram\n",
    "The audiogram is the standard clinical test for determining the sensitivity of hearing. The sounds it uses are pure tones, or sine waves. These sine waves can be described in terms of their frequency and their level. Frequency is the rate at which the sound wave oscillates. Frequency is measured in hertz (Hz), and is related to the pitch of the tone (how 'high' it is, perceptually). Level is measured in decibels (dB), and describes the energy of the sound wave on a logarithmic scale.\n",
    "\n",
    "Our auditory systems are not equally sensitive to all sound frequencies. The structures of the outer and middle ear have particular resonance frequencies which mean that some sound frequencies are transmitted to the inner ear more effectively than others. Consequently, we hear those frequencies more easily. Some auditory disorders also have frequency-dependent effects on hearing. As a result, the perceptual loudness of a pure tone depends both on its frequency and its level. The audiogram measures this sensitivity by finding the minimum sound level required to detect a tone (the threshold), and plotting how this varies with frequency. The resulting graph gives us some important insights into our auditory systems, and is useful for diagnosing auditory disorders.\n",
    "\n",
    "## How this class works\n",
    "The class is structured as a series of \"cells\". Each cell contains computer code that you can run to perform tasks like collecting data and analysing data. To complete the class, you need to click in each cell in turn and perform the associated task. Start now by clicking in the cell below, which contains the initial setup code to start the experiment. Click in the cell, then click its Play button on the left-hand side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial setup\n",
    "# To run the code in this cell, click on this text\n",
    "# <--- Then click on the Play button on the left\n",
    "# The code will take a few seconds to run.\n",
    "# When you see \"Setup complete\", you can move to the next cell\n",
    "\n",
    "!pip install git+https://github.com/beniamino38/jupyter-psychoacoustics.git >/dev/null\n",
    "from psychoacoustics.jupyterpsych import JupyterPsych\n",
    "from psychoacoustics.audiogram import *\n",
    "from psychoacoustics.sound import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration\n",
    "To determine sensitivity to sound level, we first need to calibrate your headphones, so we know what sound level is being presented. For best results, you can download a sound meter app for your phone, and use that to measure the sound level produced by your headphones. Alternatively, you can make use of the interesting fact that, when you rub your hands together briskly (but not so much that they get hot!) the resulting sound level is approximately 60dB SPL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell by clicking here,\n",
    "# <--- then pressing Play\n",
    "\n",
    "jp = JupyterPsych()\n",
    "jp.calibrate_sound_level()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring your own thresholds\n",
    "Click here to open the audiogram page. Put on the headphones and click 'Play sound'. You will hear a constant background noise and an intermittent pure tone. The sliders at the top allow you to control the frequency and level of the pure tone. Begin with the default frequency (1,000Hz), and adjust the level until the tone is barely audible. Check carefully that the tone is just detectable. When you're satisfied, click 'Record data point' to plot this threshold on the graph.\n",
    "\n",
    "Now choose another frequency (say 2,000Hz). Again, carefully adjust the level until the tone is barely audible, and record the data point. Carry on doing this with frequencies that are roughly evenly spaced on the logarithmic frequency scale (for example, record one point at one each of the vertical grid lines) until you have plotted your whole audible range. Now focus more carefully on any parts of your curve that seem to have interesting structure -- in particular, you may need to plot a few extra points between 1,000Hz and 10,000Hz to get a smooth curve. If the result is jagged, you may need to repeat your measurements in some places.\n",
    "\n",
    "Finally, to plot the low and high frequency ends of the curve, try a different approach: set the level to maximum (60dB) and either lower or raise the frequency until the sound is just audible. Record these points on the graph as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell by clicking here,\n",
    "# <--- then pressing Play\n",
    "\n",
    "audiogram_expt = AudiogramExpt(jupyterpsych=jp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Right-click the graph, download it, and copy it into your assessment document.**\n",
    "\n",
    "**Q1: What is the lowest frequency you can detect? What is the highest frequency?**\n",
    "\n",
    "**Q2: To what frequency is your auditory system most sensitive?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing your thresholds with standard values\n",
    "You will already have seen that your thresholds vary with frequency. To understand whether your hearing is good or poor (or to diagnose a hearing disorder), we need to compare your thresholds with standard values. Run the cell to compare your values with a graph of typical threshold values for young listeners with normal hearing (obtained by averaging together the curves of many listeners). Compare the shape of your curve with the standard one and observe any differences.\n",
    "\n",
    "**Q4: At what frequencies is your hearing better or worse than the standard audiogram? Why does your hearing sensitivity vary with frequency?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell by clicking here,\n",
    "# <--- then pressing Play\n",
    "\n",
    "audiogram_expt.plot_standard_thresholds()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The clinical audiogram\n",
    "\n",
    "The clinical audiogram subtracts the standard threshold curve from your thresholds and plot the difference (in dB)effectively turning the ‘U’-shaped, frequency-dependent audiogram into a set of points arranged horizontally. Note that the resulting graph is conventionally plotted with larger values at the bottom. This is how a clinical audiometer works and shows how close to 'normal' your hearing is. Note, however, that quite large deviations from standard thresholds would be regarded clinically as falling within the normal range. And, of course, the methodology we use here is rather rough, and is not adequate to make a real clinical diagnosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell by clicking here,\n",
    "# <--- then pressing Play\n",
    "\n",
    "audiogram_expt.plot_clinical_audiogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3: What does a hearing level difference value of 0 dB mean? What about values lower than 0 dB? Values greater than 0 dB?**\n",
    "\n",
    "**Q4: At what frequencies is your hearing better or worse than the standard audiogram? Why does your hearing sensitivity vary with frequency?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hearing disorders\n",
    "\n",
    "The audiogram is a useful tool for diagnosing hearing disorders. Run the next cell to see some examples.\n",
    "\n",
    "**Conductive hearing loss** happens when sound is poorly conducted through the eardrum and middle ear. It can be caused by otitis media (glue ear), calcification of the ossicles, or blockage of the outer ear (e.g. by earwax). It makes sounds of all frequencies quieter than usual. To test for conductive hearing loss, a tuning fork can be placed on the skull the behind the ear (Rinne's test). This restores hearing because sound is transmitted to the inner ear directly by the skull (bone conduction).\n",
    "\n",
    "**Presbyacusis (or presbycusis)** is the normal degradation of hearing with age. A number of factors can contribute to age-related hearing disorders from reduced performance of mechanisms in the middle and inner ear to changes in the numbers and properties of neurons in the auditory pathway. But presbyacusis arises principally from the progressive loss of sensory hair cells in the cochlea, the hearing part of the inner ear. It reduces auditory sensitivity, particularly at high frequencies. It is also often associated with tinnitus — the perception of sound when no sound is present.\n",
    "\n",
    "**Noise-induced hearing loss** reflects damage to the cochlea which is the result of exposure to excessively loud noises. This tends to be most severe where the auditory system was previously most sensitive, resulting in a 'notch' (poor sensitivity) around 4,000Hz. Like presbyacusis, high-frequency noise-induced hearing loss is often associated with tinnitus. It is likely that the progressive exposure to 'noise' over the course of a lifetime gives rise to presbyacusis.\n",
    "\n",
    "Click on 'Hearing disorders'. There are three audiograms, labelled A, B and C. They correspond to presbyacusis, conductive hearing loss and noise-induced hearing loss (though not in that order).\n",
    "\n",
    "**Q5: Which audiogram (A, B, C) shows which disorder?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell by clicking here,\n",
    "# <--- then pressing Play\n",
    "\n",
    "plot_disorders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why do pure tone thresholds matter?\n",
    "\n",
    "We very rarely encounter pure tones in real life. So what can pure tone thresholds tell us about our everyday hearing? Fourier theory tells us that any (periodic) sound can be thought of as a sum of sinusoidal components. Sinusoidal components are simply pure tones. Furthermore, the cochlea — the hearing part of our inner ear — does a similar frequency decomposition, with the different frequency components of complex sounds being extracted at different points along its length. This means that our perception of complex, natural sounds such as speech can (to an extent) be predicted from our sensitivity to pure tones. Thus, we can use the audiogram to understand how hearing deficits alter the perception of sound.\n",
    "\n",
    "## Periodic sounds\n",
    "\n",
    "Run the cell below and play the sound. You will hear a sound composed of 10 pure tone components (like the pure tones you used in the audiogram). Notice that this sounds like a single 'voice', even though it is made up of 10 components. Decrease or increase the number of components by clicking the buttons. Notice that the high frequency components don't make a cacophony of perceptually separate high-pitched sounds, but contribute to the overall percept of a relatively low-pitch sound. Musically trained people generally perceive that the pitch of the sound is fixed, and adding additional components ('harmonics') changes the 'timbre' or quality of the sound. But you may perceive things differently.\n",
    "\n",
    "**Q6: How does the pitch of the sound change as you add sinusoidal components? How does the timbre change?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell by clicking here,\n",
    "# <--- then pressing Play\n",
    "\n",
    "SquareWave();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complete sound is known as a square wave. Its waveform is very different from that of a sine wave, but (like all sounds) it can be produced by simply adding together appropriately chosen pure tones. Fourier theory allows us to calculate which sinusoidal components are needed to build up the square wave.\n",
    "\n",
    "The graph shows you the waveforms of all the components, and how they sum to produce the complete waveform (thick black line). The fundamental frequency of the square wave is 500Hz, but numerous higher frequency components are needed to build up the complete square wave.\n",
    "\n",
    "Although this is a \"low-frequency sound\" (dominated by its fundamental frequency, 500Hz), it contains high-frequency components which affect how it sounds. Just like the square wave, human voices are low-pitch, but have high-frequency components. As a result, presbyacusis, even though it affects only high-frequency hearing,  impairs older people's ability to accurately hear and understand both low- and high-pitch sounds. This is why presbyacusis affects our ability to understand speech.\n",
    "\n",
    "**Q7: What is the highest frequency component that contributes to your perception of the square wave? How does this compare to the lowest frequency in the sound?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex, natural sounds\n",
    "\n",
    "We can also use Fourier theory to investigate the frequency components of a complex sound. Run the next cell to see the spectrogram of a complex sound. Each row of the spectrogram shows how the level of a single frequency component of the sound changes over time.\n",
    "\n",
    "This particular spectrogram shows a complex sound -- a human voice. The voice is dominated by low-frequency components (at the bottom of the graph), but -- just like the square wave -- it contains components at frequencies as high as 20,000Hz (vertical bands). \n",
    "\n",
    "Press the numbered buttons to see the effect of modifying the number of Fourier components in the sound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaturalSound();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated presbyacusis\n",
    "\n",
    "Even though voices have relatively a low pitch (males typically lower than females and adults lower than children), speech sounds contain frequency components that span a wide range. Therefore, high-frequency components substantially affect the intelligibility of speech. Play the 'Simulated presbyacusis' sound. This is the same speech sample as above, but it has been filtered using the audiogram of someone with presbyacusis. Notice how the simulated presbyacusis impairs your ability to understand the speech.\n",
    "\n",
    "**Q8: Which elements of speech are most affected by presbyacusis? How does this relate to the typical audiogram of presbyacusis?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
